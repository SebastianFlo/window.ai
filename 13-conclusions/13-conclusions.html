<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>window.ai</title>
    <link rel="stylesheet" href="../style.css" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link
      href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap"
      rel="stylesheet"
    />
  </head>
  <body>
    <main>
      <h1>Conclusions</h1>

      <h3>Pros</h3>
      - Free (for now at least) - Uniform JS API - Simplified language model
      (The complicated stuff is abstracted in the browser) - Privacy: Local
      processing of sensitive data (in theory this should never leave the
      device) - Speed?: Local device should be faster in case of slow network -
      Offline usage (remote areas, festivals etc...) - Uses device energy: More
      sustainable (no coal powered AI needed)

      <h3>Cons</h3>
      - Not as good as the larger models - Only in chrome for now. Will other
      browsers use this or their own, with their own version (canAIuse .com ?
      :D) - Currently changes very fast

      <h3>Predictions</h3>

      - These local models will only get better - Could become user defined
      (based on brower, or what the model the user decides to load in their
      browser) - Endless applications, like summarising data, extracting
      payloads from text

      <h3>Connect</h3>
      <li>
        <a href="https://www.linkedin.com/in/sebastianflorian/"
          >https://www.linkedin.com/in/sebastianflorian/</a
        >
      </li>

      <h3>Resources</h3>

      <p>This repo:</p>
      <li>
        <a href="https://github.com/SebastianFlo/window.ai"
          >https://github.com/SebastianFlo/window.ai</a
        >
      </li>

      <p>References:</p>

      <ul>
        <li>https://github.com/tomayac</li>
        <li>https://github.com/tomayac/prompt-api-playground</li>
        <li>https://developer.chrome.com/docs/ai/built-in</li>
        <li>https://github.com/webmachinelearning/prompt-api</li>
        <li>https://developer.chrome.com/docs/ai/built-in-apis#prompt_api</li>
        <li>
          https://dev.to/grahamthedev/windowai-running-ai-locally-from-devtools-202j
        </li>
        <li>https://tyingshoelaces.com/blog/chrome-ai-prompt-api</li>
        <li>
          https://labs.thinktecture.com/local-small-language-models-in-the-browser-a-first-glance-at-chromes-built-in-ai-and-prompt-api-with-gemini-nano/
        </li>
        <li>https://developer.chrome.com/docs/ai/ai-session-management</li>
        <li>https://developer.chrome.com/docs/ai/render-llm-responses</li>
        https://ai-streaming-parser.glitch.me/
      </ul>
    </main>

    <script></script>
    <script src="../audio-slides.js"></script>
  </body>
</html>
